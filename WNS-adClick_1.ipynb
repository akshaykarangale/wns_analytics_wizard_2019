{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import catboost as cbst\n",
    "import gensim\n",
    "pd.options.display.max_columns=100\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "tqdm_notebook().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "orig_train = pd.read_csv(\"train.csv\")\n",
    "orig_view_log = pd.read_csv(\"view_log.csv\")\n",
    "orig_item_data = pd.read_csv(\"item_data.csv\")\n",
    "orig_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train['impression_time'] = pd.to_datetime(orig_train['impression_time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "orig_test['impression_time'] = pd.to_datetime(orig_test['impression_time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "orig_view_log['server_time'] = pd.to_datetime(orig_view_log['server_time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "train_view_log = orig_view_log[orig_view_log['server_time'] <= \"2018-11-14\"]\n",
    "train_view_log.sort_values(\"server_time\", inplace=True)\n",
    "orig_view_log.sort_values(\"server_time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cat_cols(df, cat_cols):\n",
    "    for c in cat_cols:\n",
    "        enc_dict = {}\n",
    "        for i, u in enumerate(df[c].unique()):\n",
    "            enc_dict[u] = i\n",
    "        df[c] = df[c].map(enc_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_features(df):\n",
    "    df['impression_min'] = df['impression_time'].dt.minute\n",
    "    df['impression_hour'] = df['impression_time'].dt.hour\n",
    "    df['impression_wkday'] = df['impression_time'].dt.weekday\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_click_td(train_, test_, cols, is_local=True, suffix=\"\"):\n",
    "    train = train_.copy()\n",
    "    test = test_.copy()\n",
    "    if is_local:\n",
    "        train['is_click_dup'] = train['is_click'].copy()\n",
    "        concat_df = pd.concat([train, test], ignore_index=True)\n",
    "        concat_df.sort_values(\"impression_time\", inplace=True)\n",
    "        concat_df['click_td' + suffix] = concat_df.groupby(by=cols)['is_click_dup'].progress_apply(lambda x: x.expanding().mean().shift())\n",
    "        train_new = concat_df[concat_df['is_click_dup'].notnull()].drop('is_click_dup', axis=1)\n",
    "        test_new = concat_df[concat_df['is_click_dup'].isnull()].drop('is_click_dup', axis=1)\n",
    "        return train_new, test_new\n",
    "    else:\n",
    "        concat_df = pd.concat([train, test], ignore_index=True)\n",
    "        concat_df.sort_values(\"impression_time\", inplace=True)\n",
    "        concat_df['click_td' + suffix] = concat_df.groupby(by=cols)['is_click'].progress_apply(lambda x: x.expanding().mean().shift())\n",
    "        train_new = concat_df[concat_df['is_click'].notnull()]\n",
    "        test_new = concat_df[concat_df['is_click'].isnull()]\n",
    "        return train_new, test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = encode_cat_cols(orig_train, cat_cols=['os_version'])\n",
    "test_df = encode_cat_cols(orig_test, cat_cols=['os_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sort_values(\"impression_time\", inplace=True)\n",
    "test_df.sort_values(\"impression_time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = build_train_features(train_df)\n",
    "test_df = build_train_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p2p_tr = train_view_log.groupby(by='user_id')['server_time'].progress_apply(lambda x: np.array(x).ptp()/np.timedelta64(1, 's')).reset_index().rename(columns={\"server_time\": \"time_ptp\"})\n",
    "user_p2p_te = orig_view_log.groupby(by='user_id')['server_time'].progress_apply(lambda x: np.array(x).ptp()/np.timedelta64(1, 's')).reset_index().rename(columns={\"server_time\": \"time_ptp\"})\n",
    "train_df = train_df.merge(user_p2p_tr, on='user_id', how='left')\n",
    "test_df = test_df.merge(user_p2p_te, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_of_user_tr = train_view_log.groupby(by='user_id', as_index=False)['session_id'].count().rename(columns={\"session_id\": \"n_views_user\"})\n",
    "views_of_user_te = orig_view_log.groupby(by='user_id', as_index=False)['session_id'].count().rename(columns={\"session_id\": \"n_views_user\"})\n",
    "train_df = train_df.merge(views_of_user_tr, on='user_id', how='left')\n",
    "test_df = test_df.merge(views_of_user_te, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat([train_df, test_df], sort=True, ignore_index=True)\n",
    "concat_df = concat_df.sort_values(\"impression_time\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df['next_impression_time'] = concat_df.groupby(by='user_id')['impression_time'].progress_apply(lambda x: x.shift(-1))\n",
    "concat_df['time_to_next_visit'] = (concat_df['next_impression_time'] - concat_df['impression_time']).dt.total_seconds()\n",
    "concat_df['last_app_code'] = concat_df.groupby(by='user_id')['app_code'].progress_apply(lambda x: x.shift())\n",
    "user_counts = concat_df.groupby(\"user_id\", as_index=False)['impression_id'].count().rename(columns={\"impression_id\": \"user_counts\"})\n",
    "concat_df['prev_impression_time'] = concat_df.groupby(by='user_id')['impression_time'].progress_apply(lambda x: x.shift())\n",
    "concat_df['sec_since_prev_impression'] = (concat_df['impression_time'] - concat_df['prev_impression_time']).dt.total_seconds()\n",
    "concat_df = concat_df.merge(user_counts, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impression_time_ptp = concat_df.groupby(by='user_id')['impression_time'].progress_apply(lambda x: np.array(x).ptp()/np.timedelta64(1, 's')).reset_index().rename(columns={\"impression_time\": \"impression_time_ptp\"})\n",
    "train_df = train_df.merge(impression_time_ptp, on='user_id', how='left')\n",
    "test_df = test_df.merge(impression_time_ptp, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id_nunique_tr = train_view_log.groupby(by='user_id')['session_id'].nunique().reset_index().rename(columns={\"session_id\": \"unique_sessions\"})\n",
    "item_id_nunique_tr = train_view_log.groupby(by='user_id')['item_id'].nunique().reset_index().rename(columns={\"item_id\": \"unique_items\"})\n",
    "session_id_nunique_te = orig_view_log.groupby(by='user_id')['session_id'].nunique().reset_index().rename(columns={\"session_id\": \"unique_sessions\"})\n",
    "item_id_nunique_te = orig_view_log.groupby(by='user_id')['item_id'].nunique().reset_index().rename(columns={\"item_id\": \"unique_items\"})\n",
    "\n",
    "train_df = train_df.merge(session_id_nunique_tr, on='user_id', how='left')\n",
    "test_df = test_df.merge(session_id_nunique_te, on='user_id', how='left')\n",
    "\n",
    "train_df = train_df.merge(item_id_nunique_tr, on='user_id', how='left')\n",
    "test_df = test_df.merge(item_id_nunique_te, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_size = 100\n",
    "concat_df['app_code_str'] = concat_df.app_code.astype(str)\n",
    "\n",
    "w2v_app_codes = concat_df.groupby(by='user_id')['app_code_str'].apply(list)\n",
    "\n",
    "longest = np.max(w2v_app_codes.apply(len))\n",
    "model = gensim.models.Word2Vec(w2v_app_codes, size=w2v_size, window=longest, workers=4, seed=123)\n",
    "\n",
    "w2v_acode = pd.DataFrame(columns=[\"app_code\"] + [\"vec_{}\".format(i+1) for i in range(w2v_size)])\n",
    "w2v_data = []\n",
    "for acode in concat_df['app_code_str'].unique():\n",
    "    try:\n",
    "        w2v_data.append([acode] + list(model.wv.get_vector(acode)))\n",
    "    except:\n",
    "        w2v_data.append([acode] + list(np.zeros(w2v_size)))\n",
    "\n",
    "w2v_acode = pd.DataFrame(w2v_data, columns=[\"app_code_str\"] + [\"vec_{}\".format(i+1) for i in range(w2v_size)])\n",
    "concat_df = concat_df.merge(w2v_acode, on='app_code_str', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df['next_impression_min'] = concat_df['next_impression_time'].dt.minute\n",
    "concat_df['next_impression_hour'] = concat_df['next_impression_time'].dt.hour\n",
    "concat_df['next_impression_wkday'] = concat_df['next_impression_time'].dt.weekday\n",
    "concat_df['prev_time_hr'] = concat_df['prev_impression_time'].dt.hour\n",
    "concat_df['prev_time_min'] = concat_df['prev_impression_time'].dt.minute\n",
    "concat_df['prev_time_wkday'] = concat_df['prev_impression_time'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = concat_df[concat_df['is_click'].notnull()].reset_index(drop=True)\n",
    "test_df = concat_df[concat_df['is_click'].isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train_df[train_df[\"impression_time\"] < \"2018-12-03\"]\n",
    "# X_test = train_df[train_df[\"impression_time\"] >= \"2018-12-03\"]\n",
    "# print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test = calc_click_td(X_train, X_test, cols=['user_id'], suffix=\"_user_id\")\n",
    "# X_train, X_test = calc_click_td(X_train, X_test, cols=['app_code'], suffix=\"_app_code\")\n",
    "# X_train, X_test = calc_click_td(X_train, X_test, cols=['user_id', 'app_code'], suffix=\"_user_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = calc_click_td(train_df, test_df, cols=['user_id'], suffix=\"_user_id\")\n",
    "train_df, test_df = calc_click_td(train_df, test_df, cols=['app_code'], suffix=\"_app_code\")\n",
    "train_df, test_df = calc_click_td(train_df, test_df, cols=['user_id', 'app_code'], suffix=\"_user_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_cb = train_df.columns.drop(['impression_id', 'impression_time','is_click', 'app_code', 'next_impression_time', 'prev_impression_time'])\n",
    "print(list(predictors_cb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = train_df.columns.drop(['impression_id', 'impression_time','is_click', 'app_code_str', 'app_code', 'next_impression_time', 'prev_impression_time'])\n",
    "print(list(predictors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((len(test_df), 1))\n",
    "for i in range(15):\n",
    "    print(\"training LGBC model {}\".format(i))\n",
    "    lgbc = lgb.LGBMClassifier(n_estimators=1000, max_depth=5, learning_rate=0.01, random_state=i, colsample_bytree=0.2, reg_lambda=15, reg_alpha=10)\n",
    "#     lgbc.fit(X_train[predictors], X_train['is_click'])\n",
    "    lgbc.fit(train_df[predictors], train_df['is_click'])\n",
    "    preds = preds + lgbc.predict_proba(test_df[predictors])[:,1].reshape(-1, 1)\n",
    "preds = preds/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc = cbst.CatBoostClassifier(random_seed=123, \n",
    "                              eval_metric='AUC', \n",
    "                              n_estimators=1100, \n",
    "                              max_depth=7, \n",
    "                              learning_rate=0.03, \n",
    "                              colsample_bylevel=0.1, reg_lambda=70)\n",
    "\n",
    "cbc.fit(train_df[predictors_cb], train_df['is_click'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cb = cbc.predict_proba(test_df[predictors_cb])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = lgbc.predict_proba(X_test[predictors])[:,1]\n",
    "# preds_tr = lgbc.predict_proba(X_train[predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.roc_auc_score(X_train['is_click'], preds_tr), metrics.roc_auc_score(X_test['is_click'], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb.plot_importance(lgbc, importance_type='gain', figsize=(10, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hmean\n",
    "sub = pd.DataFrame()\n",
    "sub['impression_id'] = test_df['impression_id'].copy()\n",
    "sub['is_click_x'] = preds\n",
    "sub['is_click_y'] = preds_cb\n",
    "hmean_preds = hmean(sub[['is_click_x', 'is_click_y']].values, axis=1)\n",
    "sub['is_click'] = hmean_preds\n",
    "sub[['impression_id', 'is_click']].to_csv(\"sub_1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
